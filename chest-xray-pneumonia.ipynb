{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nimport tensorflow as tf\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-01T01:01:09.965091Z","iopub.execute_input":"2024-03-01T01:01:09.965426Z","iopub.status.idle":"2024-03-01T01:01:21.314444Z","shell.execute_reply.started":"2024-03-01T01:01:09.965389Z","shell.execute_reply":"2024-03-01T01:01:21.313578Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-01 01:01:12.115128: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-01 01:01:12.115276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-01 01:01:12.250067: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_data(img_dims, batch_size):\n    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=.3, vertical_flip=True)\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    \n    train_generator = train_datagen.flow_from_directory(\n        directory='/kaggle/input/chest-xray-pneumonia/chest_xray/train/',\n        target_size=(img_dims, img_dims),\n        batch_size=batch_size,\n        class_mode='binary',\n        shuffle=True\n    )\n    \n    test_generator = test_datagen.flow_from_directory(\n        directory='/kaggle/input/chest-xray-pneumonia/chest_xray/test/',\n        target_size=(img_dims, img_dims),\n        batch_size=batch_size,\n        class_mode='binary',\n        shuffle=True\n    )\n    \n    testData = []\n    testLabels = []\n    \n    for condition in ['NORMAL', 'PNEUMONIA']:\n        for img_name in os.listdir('/kaggle/input/chest-xray-pneumonia/chest_xray/test/' + condition):\n            img_path = os.path.join('/kaggle/input/chest-xray-pneumonia/chest_xray/test/', condition, img_name)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = img.astype('float32') / 255\n            testData.append(img)\n            if condition == 'NORMAL':\n                label = 0\n            elif condition == 'PNEUMONIA':\n                label = 1\n            testLabels.append(label)\n\n    testData = np.array(testData)\n    testLabels = np.array(testLabels)\n    \n    return train_generator, test_generator, testData, testLabels\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T01:21:23.842131Z","iopub.execute_input":"2024-03-01T01:21:23.842467Z","iopub.status.idle":"2024-03-01T01:21:23.850814Z","shell.execute_reply.started":"2024-03-01T01:21:23.842443Z","shell.execute_reply":"2024-03-01T01:21:23.849549Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define input shape\ninput_shape = (150, 150, 3)\n\n# Process the data\ntrain_generator, test_generator, testData, testLabels = process_data(150, 8)\n\n# Define the model\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n\n# Train the model\nnum_epochs = 10\nverbose = 1\nsteps_per_epoch = len(train_generator)\nvalidation_steps = len(test_generator)\n\nhistory = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=verbose, validation_data=test_generator, validation_steps=validation_steps)\n\n# Evaluate the model\npred = model.predict(testData)\npredicted_labels = np.round(pred)\naccuracy = accuracy_score(testLabels, predicted_labels) * 100\n\nprint(\"Accuracy: {:.2f}%\".format(accuracy))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T01:33:09.430521Z","iopub.execute_input":"2024-03-01T01:33:09.430881Z","iopub.status.idle":"2024-03-01T01:49:31.157294Z","shell.execute_reply.started":"2024-03-01T01:33:09.430857Z","shell.execute_reply":"2024-03-01T01:49:31.156228Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 5216 images belonging to 2 classes.\nFound 624 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 238ms/step - accuracy: 0.7456 - loss: 0.7772 - val_accuracy: 0.7917 - val_loss: 0.4295\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 3/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 236ms/step - accuracy: 0.8430 - loss: 0.3675 - val_accuracy: 0.7628 - val_loss: 0.4646\nEpoch 4/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 5/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 237ms/step - accuracy: 0.8783 - loss: 0.2895 - val_accuracy: 0.8349 - val_loss: 0.3900\nEpoch 6/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 7/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 237ms/step - accuracy: 0.8799 - loss: 0.2731 - val_accuracy: 0.7660 - val_loss: 0.5365\nEpoch 8/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 9/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 235ms/step - accuracy: 0.8968 - loss: 0.2595 - val_accuracy: 0.8510 - val_loss: 0.4067\nEpoch 10/10\n\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step\nAccuracy: 85.10%\n","output_type":"stream"}]}]}